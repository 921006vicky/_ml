copy陳穎辰

# 習題 7：使用 micrograd 重做函數優化問題（梯度下降）

## 問題描述

本習題延續習題 1 的數學函數：

\[
f(x, y, z) = x^2 + y^2 + z^2 - 2x - 4y - 6z + 8
\]

在習題 1 中，我們使用爬山演算法尋找函數的最小值。  
本習題改為使用 **微分自動求導（autograd）框架 micrograd**，利用梯度下降法來最小化此目標函數。

---

## 函數性質

這是一個簡單的三維二次函數，具有明確的最小值，可解析求得最小點為：

\[
x=1, \quad y=2, \quad z=3
\]

---

## 解法原理：使用 micrograd 實作自動微分 + 梯度下降

### micrograd 簡介

[micrograd](https://github.com/karpathy/micrograd) 是一個簡潔的自動微分引擎，核心是 `Value` 類別：

- 支援標量運算：加減乘除、指數等
- 自動建立計算圖並追蹤導數
- 使用 `.backward()` 執行反向傳播計算梯度

---

## 解法步驟

1. 建立變數 `x`, `y`, `z` 為 `Value` 物件
2. 定義損失函數：\( f(x, y, z) \)
3. 每次迭代：
    - 重設梯度為 0
    - 執行 forward pass 和 `loss.backward()`
    - 使用學習率更新參數：\( x -= \eta \cdot \frac{\partial f}{\partial x} \)

